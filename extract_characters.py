#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import json
from collections import defaultdict
import argparse

def should_process_file(file_path):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†è¯¥æ–‡ä»¶"""
    # æ£€æŸ¥æ‰©å±•å
    valid_extensions = {'.cs', '.json', '.txt', '.md', '.prefab', '.unity', '.asset'}
    _, ext = os.path.splitext(file_path.lower())

    if ext not in valid_extensions:
        return False

    # æ’é™¤ä¸éœ€è¦çš„æ–‡ä»¶
    exclude_patterns = [
        'Library/', 'Temp/', 'Build/', '.git/',
        '.meta', '.dll', '.exe', 'packages-lock.json',
        'DOTween', 'TextMesh Pro/Resources/', 'TextMesh Pro/Sprites/'
    ]

    for pattern in exclude_patterns:
        if pattern in file_path:
            return False

    return True

def extract_characters_from_file(file_path):
    """ä»å•ä¸ªæ–‡ä»¶ä¸­æå–å­—ç¬¦"""
    characters = set()
    char_frequency = defaultdict(int)

    try:
        # å°è¯•ä¸åŒçš„ç¼–ç æ–¹å¼è¯»å–æ–‡ä»¶
        content = None
        for encoding in ['utf-8', 'gbk', 'latin-1']:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                break
            except UnicodeDecodeError:
                continue

        if content is None:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–æ–‡ä»¶ {file_path}")
            return characters, char_frequency

        # æå–å­—ç¬¦
        for char in content:
            # è·³è¿‡æ§åˆ¶å­—ç¬¦ï¼ˆé™¤äº†å¸¸ç”¨ç©ºç™½å­—ç¬¦ï¼‰
            if ord(char) < 32 and char not in ['\n', '\r', '\t']:
                continue

            characters.add(char)
            char_frequency[char] += 1

        print(f"å¤„ç†æ–‡ä»¶: {os.path.basename(file_path)} ({len(characters)} ä¸ªå”¯ä¸€å­—ç¬¦)")

    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

    return characters, char_frequency

def categorize_characters(characters):
    """å°†å­—ç¬¦åˆ†ç±»"""
    categories = {
        'ascii_letters': set(),
        'ascii_digits': set(),
        'ascii_symbols': set(),
        'chinese': set(),
        'chinese_symbols': set(),
        'whitespace': set(),
        'other': set()
    }

    for char in characters:
        code = ord(char)

        if 'A' <= char <= 'Z' or 'a' <= char <= 'z':
            categories['ascii_letters'].add(char)
        elif '0' <= char <= '9':
            categories['ascii_digits'].add(char)
        elif 32 <= code <= 126:  # å¯æ‰“å°ASCII
            categories['ascii_symbols'].add(char)
        elif 0x4E00 <= code <= 0x9FFF:  # CJKç»Ÿä¸€æ±‰å­—
            categories['chinese'].add(char)
        elif 0x3000 <= code <= 0x303F:  # CJKç¬¦å·å’Œæ ‡ç‚¹
            categories['chinese_symbols'].add(char)
        elif char in [' ', '\t', '\n', '\r']:
            categories['whitespace'].add(char)
        else:
            categories['other'].add(char)

    return categories

def generate_character_file(all_characters, char_frequency, output_file):
    """ç”Ÿæˆå­—ç¬¦æ–‡ä»¶"""

    # åˆ†ç±»å­—ç¬¦
    categories = categorize_characters(all_characters)

    # å‡†å¤‡è¾“å‡ºå†…å®¹
    lines = []

    # æ–‡ä»¶å¤´
    lines.append("# ä»WildFriendsAllianceé¡¹ç›®ä¸­æå–çš„æ‰€æœ‰å­—ç¬¦")
    lines.append(f"# ç”Ÿæˆæ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append(f"# æ€»å”¯ä¸€å­—ç¬¦æ•°: {len(all_characters)}")
    lines.append(f"# æ€»å‡ºç°æ¬¡æ•°: {sum(char_frequency.values())}")
    lines.append("")

    # ASCIIå­—æ¯
    if categories['ascii_letters']:
        lines.append("# === ASCIIå­—æ¯ ===")
        sorted_letters = sorted(categories['ascii_letters'])
        lines.append(''.join(sorted_letters))
        lines.append("")

    # ASCIIæ•°å­—
    if categories['ascii_digits']:
        lines.append("# === ASCIIæ•°å­— ===")
        sorted_digits = sorted(categories['ascii_digits'])
        lines.append(''.join(sorted_digits))
        lines.append("")

    # ASCIIç¬¦å·
    if categories['ascii_symbols']:
        lines.append("# === ASCIIç¬¦å· ===")
        sorted_symbols = sorted(categories['ascii_symbols'])
        lines.append(''.join(sorted_symbols))
        lines.append("")

    # ä¸­æ–‡å­—ç¬¦
    if categories['chinese']:
        lines.append("# === ä¸­æ–‡å­—ç¬¦ ===")
        sorted_chinese = sorted(categories['chinese'])
        # æ¯è¡Œ80ä¸ªå­—ç¬¦ï¼Œä¾¿äºé˜…è¯»
        chinese_text = ''.join(sorted_chinese)
        for i in range(0, len(chinese_text), 80):
            lines.append(chinese_text[i:i+80])
        lines.append("")

    # ä¸­æ–‡ç¬¦å·
    if categories['chinese_symbols']:
        lines.append("# === ä¸­æ–‡ç¬¦å· ===")
        sorted_chinese_symbols = sorted(categories['chinese_symbols'])
        lines.append(''.join(sorted_chinese_symbols))
        lines.append("")

    # ç©ºç™½å­—ç¬¦
    if categories['whitespace']:
        lines.append("# === ç©ºç™½å­—ç¬¦ ===")
        whitespace_display = []
        for char in sorted(categories['whitespace']):
            if char == ' ':
                whitespace_display.append('ç©ºæ ¼')
            elif char == '\t':
                whitespace_display.append('åˆ¶è¡¨ç¬¦')
            elif char == '\n':
                whitespace_display.append('æ¢è¡Œç¬¦')
            elif char == '\r':
                whitespace_display.append('å›è½¦ç¬¦')
            else:
                whitespace_display.append(f'U+{ord(char):04X}')
        lines.append(' '.join(whitespace_display))
        lines.append("")

    # å…¶ä»–å­—ç¬¦
    if categories['other']:
        lines.append("# === å…¶ä»–å­—ç¬¦ ===")
        sorted_other = sorted(categories['other'])
        lines.append(''.join(sorted_other))
        lines.append("")

    # ä½¿ç”¨é¢‘ç‡æœ€é«˜çš„å­—ç¬¦
    lines.append("# === ä½¿ç”¨é¢‘ç‡æœ€é«˜çš„50ä¸ªå­—ç¬¦ ===")
    sorted_by_freq = sorted(char_frequency.items(), key=lambda x: x[1], reverse=True)
    for i, (char, freq) in enumerate(sorted_by_freq[:50]):
        if char == '\n':
            char_display = '\\n'
        elif char == '\r':
            char_display = '\\r'
        elif char == '\t':
            char_display = '\\t'
        elif char == ' ':
            char_display = 'ç©ºæ ¼'
        else:
            char_display = char
        lines.append(f"# {char_display} (å‡ºç°{freq}æ¬¡)")

    lines.append("")
    lines.append("# === æ‰€æœ‰å­—ç¬¦ï¼ˆç”¨äºTextMesh Proï¼‰ ===")

    # ä¸ºTextMesh Proç”Ÿæˆå­—ç¬¦ä¸²ï¼ˆæ’é™¤æ§åˆ¶å­—ç¬¦ï¼‰
    tmp_chars = []
    for char in sorted(all_characters):
        if char not in ['\n', '\r', '\t'] and ord(char) >= 32:
            tmp_chars.append(char)

    # æ¯è¡Œ100ä¸ªå­—ç¬¦
    tmp_text = ''.join(tmp_chars)
    for i in range(0, len(tmp_text), 100):
        lines.append(tmp_text[i:i+100])

    # å†™å…¥æ–‡ä»¶
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        print(f"\nå­—ç¬¦æ–‡ä»¶å·²ç”Ÿæˆ: {output_file}")
        print(f"æ€»å…±åŒ…å« {len(all_characters)} ä¸ªå”¯ä¸€å­—ç¬¦")
        return True
    except Exception as e:
        print(f"å†™å…¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='ä»é¡¹ç›®æ–‡ä»¶ä¸­æå–æ‰€æœ‰å­—ç¬¦')
    parser.add_argument('--output', '-o', default='characters.txt', help='è¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--chinese-only', action='store_true', help='ä»…æå–ä¸­æ–‡å­—ç¬¦')

    args = parser.parse_args()

    # æœç´¢ç›®å½•
    search_dirs = ['.', 'questions', 'Assets']

    all_characters = set()
    char_frequency = defaultdict(int)

    print("å¼€å§‹æå–é¡¹ç›®ä¸­çš„æ‰€æœ‰å­—ç¬¦...")

    file_count = 0
    for search_dir in search_dirs:
        if not os.path.exists(search_dir):
            continue

        for root, dirs, files in os.walk(search_dir):
            # æ’é™¤ä¸éœ€è¦çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in ['Library', 'Temp', 'Build', '.git']]

            for file in files:
                file_path = os.path.join(root, file)

                if should_process_file(file_path):
                    chars, freq = extract_characters_from_file(file_path)
                    all_characters.update(chars)

                    for char, count in freq.items():
                        char_frequency[char] += count

                    file_count += 1

    print(f"\nå¤„ç†äº† {file_count} ä¸ªæ–‡ä»¶")

    # å¦‚æœåªè¦ä¸­æ–‡å­—ç¬¦ï¼Œè¿‡æ»¤ç»“æœ
    if args.chinese_only:
        chinese_chars = set()
        chinese_freq = defaultdict(int)

        for char in all_characters:
            code = ord(char)
            if 0x4E00 <= code <= 0x9FFF or 0x3000 <= code <= 0x303F:
                chinese_chars.add(char)
                chinese_freq[char] = char_frequency[char]

        all_characters = chinese_chars
        char_frequency = chinese_freq
        args.output = 'chinese_characters.txt'
        print(f"è¿‡æ»¤åä»…ä¿ç•™ä¸­æ–‡å­—ç¬¦: {len(all_characters)} ä¸ª")

    # ç”Ÿæˆå­—ç¬¦æ–‡ä»¶
    success = generate_character_file(all_characters, char_frequency, args.output)

    if success:
        print(f"\nâœ… å­—ç¬¦æå–å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {args.output}")
        print(f"ğŸ”¤ å”¯ä¸€å­—ç¬¦æ•°: {len(all_characters)}")
        print(f"ğŸ“Š æ€»å‡ºç°æ¬¡æ•°: {sum(char_frequency.values())}")

        # æ˜¾ç¤ºå„ç±»å­—ç¬¦ç»Ÿè®¡
        categories = categorize_characters(all_characters)
        print(f"\nğŸ“ˆ å­—ç¬¦åˆ†ç±»ç»Ÿè®¡:")
        print(f"  ASCIIå­—æ¯: {len(categories['ascii_letters'])}")
        print(f"  ASCIIæ•°å­—: {len(categories['ascii_digits'])}")
        print(f"  ASCIIç¬¦å·: {len(categories['ascii_symbols'])}")
        print(f"  ä¸­æ–‡å­—ç¬¦: {len(categories['chinese'])}")
        print(f"  ä¸­æ–‡ç¬¦å·: {len(categories['chinese_symbols'])}")
        print(f"  ç©ºç™½å­—ç¬¦: {len(categories['whitespace'])}")
        print(f"  å…¶ä»–å­—ç¬¦: {len(categories['other'])}")

if __name__ == '__main__':
    main()